{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "341003e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import ssl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "import re\n",
    "import tempfile\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abad1109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hikar\\anaconda3\\envs\\mmediting_1\\lib\\site-packages\\mmcv\\__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n"
     ]
    }
   ],
   "source": [
    "from mmflow.apis import init_model, inference_model\n",
    "from mmflow.datasets import visualize_flow, write_flow\n",
    "import mmcv\n",
    "config_file = r\"C:\\Users\\hikar\\Documents\\pwcnet_ft_4x1_300k_sintel_final_384x768.py\"\n",
    "checkpoint_file = r\"C:\\Users\\hikar\\Documents\\pwcnet_ft_4x1_300k_sintel_final_384x768.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba8e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f26c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch videos from UCF101 dataset\n",
    "UCF_ROOT = \"https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/\"\n",
    "_VIDEO_LIST = None\n",
    "unverified_context = ssl._create_unverified_context()\n",
    "UCF_DATA_FOLDER = r\"C:\\Users\\hikar\\Documents\\UCF_101\"\n",
    "\n",
    "def list_ucf_videos():\n",
    "    global _VIDEO_LIST\n",
    "    if not _VIDEO_LIST:\n",
    "        index = request.urlopen(UCF_ROOT, context=unverified_context).read().decode(\"utf-8\")\n",
    "        videos = re.findall(\"(v_[\\w_]+\\.avi)\", index)\n",
    "        _VIDEO_LIST = sorted(set(videos))\n",
    "    return list(_VIDEO_LIST)\n",
    "  \n",
    "def path_modify(video):\n",
    "  action_dir = video.split('_')[1]\n",
    "  if action_dir == \"HandstandPushups\":\n",
    "      action_dir = \"HandStandPushups\"\n",
    "      text_list = video.split('_')\n",
    "      base_video_path = text_list[0]+ '_' + action_dir + '_' + text_list[2] + '_' + text_list[3]\n",
    "      print(base_video_path)\n",
    "      return base_video_path\n",
    "  \n",
    "  return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0a9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ucf_action_list():\n",
    "  cache_list = []\n",
    "  video_list = list_ucf_videos()\n",
    "  for path in video_list:\n",
    "    action_dir = path.split('_')[1]\n",
    "    if action_dir == \"HandstandPushups\":\n",
    "      action_dir = \"HandStandPushups\"\n",
    "    cache_list.append(action_dir)\n",
    "  cache_list = set(cache_list)\n",
    "  cache_list = list(cache_list)\n",
    "  cache_list.sort()\n",
    "  return cache_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620562e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9a43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flo_out(model,img1,img2,img3):#コードかえる\n",
    "  \n",
    "\n",
    "    \n",
    "  base_path_1 = os.path.splitext(os.path.basename(img1))[0]\n",
    "  base_path_2 = os.path.splitext(os.path.basename(img2))[0]\n",
    "  base_path_3 = os.path.splitext(os.path.basename(img3))[0]\n",
    "\n",
    "# D:\\GR_data\\capture_all_frame\\Fixed\\Archery\\frames_v_Archery_g02_c01\n",
    "#\"D:\\GR_data\\write_flow_folder\"\n",
    "\n",
    "  flo_root_folder = r\"F:\\Users\\hikar\\GR_data\\write_flow_folder\" #変更可\n",
    "  split_path_list = img1.split(os.sep)\n",
    "  flo_dir_name = os.path.join(flo_root_folder,split_path_list[3],split_path_list[4],split_path_list[5])#変更可\n",
    "  \n",
    "  if not os.path.isdir(flo_dir_name):\n",
    "    os.makedirs(flo_dir_name)\n",
    "#     print(flo_dir_name)\n",
    "\n",
    "  flo_name_12 = os.path.join(flo_dir_name,base_path_1+base_path_2+\".flo\")\n",
    "#   print(flo_name_12)\n",
    "  flo_name_23 = os.path.join(flo_dir_name,base_path_2+base_path_3+\".flo\")\n",
    "#   print(flo_name_23)\n",
    "\n",
    "  if not os.path.exists(flo_name_12):\n",
    "    result_12 = inference_model(model, img1, img2)\n",
    "    write_flow(result_12,flow_file = flo_name_12)\n",
    "    \n",
    "  if not os.path.exists(flo_name_23):\n",
    "    result_23 = inference_model(model, img2, img3)\n",
    "    write_flow(result_23,flow_file = flo_name_23)\n",
    "\n",
    "  # visualize_flow(result_12, save_file='flow_map_12.png')\n",
    "  # visualize_flow(-result_12,save_file = 'flow_map_reverse.png')\n",
    "  # visualize_flow(result_23,save_file = \"flow_map_23.png\")\n",
    "  return flo_name_12,flo_name_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3506fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_values_closeto_0(flow_map12,flow_map23):\n",
    "#   print(flow_map12)\n",
    "#   print(flow_map23)\n",
    "    \n",
    "  condition_12_1 = (flow_map12 < 0.01)\n",
    "  condition_12_2 = (flow_map12 > -0.01)\n",
    "  condition_12 = condition_12_1 & condition_12_2\n",
    "\n",
    "  condition_23_1 = (flow_map23 < 0.01)\n",
    "  condition_23_2 = (flow_map23 > 0.01)\n",
    "  condition_23 = condition_23_1 & condition_23_2\n",
    "\n",
    "  flow_map12[condition_12] = 0\n",
    "  flow_map23[condition_23] = 0\n",
    "\n",
    "  return flow_map12,flow_map23\n",
    "\n",
    "\n",
    "def read_2_flo(flow12_path,flow23_path):\n",
    "#   print(flow23_path)\n",
    "  flow_map12 = cv2.readOpticalFlow(flow12_path)\n",
    "  flow_map23 = cv2.readOpticalFlow(flow23_path)\n",
    "\n",
    "  flow_map12,flow_map23 = remove_values_closeto_0(flow_map12,flow_map23)\n",
    "\n",
    "\n",
    "  return flow_map12,flow_map23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84ca2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nan_to_0(flow_magnitude):\n",
    "  nans = np.isnan(flow_magnitude)\n",
    "  if np.any(nans):\n",
    "      nans = np.where(nans)\n",
    "      flow_magnitude[nans] = 0.\n",
    "  \n",
    "  return flow_magnitude\n",
    "\n",
    "\n",
    "def flow_magnitude_out(flow_map12,flow_map23):\n",
    "  flow_map_12_channel_0 = flow_map12[:,:,0]\n",
    "  flow_map_12_channel_1 = flow_map12[:,:,1]\n",
    "  \n",
    "  flow_map_23_channel_0 = flow_map23[:,:,0]\n",
    "  flow_map_23_channel_1 = flow_map23[:,:,1]\n",
    "  \n",
    "  flow_magnitude_12, _ = cv2.cartToPolar(flow_map_12_channel_0, flow_map_12_channel_1)\n",
    "  flow_magnitude_23, _ = cv2.cartToPolar(flow_map_23_channel_0, flow_map_23_channel_1)\n",
    "  # A couple times, we've gotten NaNs out of the above...\n",
    "  \n",
    "  flow_magnitude_12 = convert_nan_to_0(flow_magnitude_12)\n",
    "  flow_magnitude_23 = convert_nan_to_0(flow_magnitude_23)\n",
    "\n",
    "  return flow_magnitude_12,flow_magnitude_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cedec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_second_frame_to_first(flow_map_origin,second_frame):\n",
    "  flow_map = copy.copy(flow_map_origin)\n",
    "  h,w = flow_map.shape[:2]\n",
    "  flow_map[:,:,0] += np.arange(w)#変換後の座標を指定\n",
    "  flow_map[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "  img2 = cv2.imread(second_frame)\n",
    "  warped_prevImg = cv2.remap(img2, flow_map, None, cv2.INTER_LINEAR)#INTER_NEAREST#INTER_AREA\n",
    "#   cv2.imwrite(\"warped_first_frame.png\",warped_prevImg)\n",
    "\n",
    "  return warped_prevImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8de75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9977897",
   "metadata": {},
   "source": [
    "# Vimeo three condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4993f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_movement_greater_than_3(flow_map,flow_magnitude):#2#(o)\n",
    "  first_bool = False\n",
    "  more_number = np.count_nonzero(flow_magnitude > 3)#ハイパーパラメータ\n",
    "  pixel_number = flow_map.shape[0] * flow_map.shape[1]# 240*320=76800\n",
    "#   print(more_number)\n",
    "#   print(pixel_number)\n",
    "#   print(more_number/pixel_number * 100)\n",
    "  if (more_number/pixel_number * 100) > 5:#ハイパーパラメータ\n",
    "    first_bool = True\n",
    "\n",
    "#  print(\"first condition is :{}\".format(more_number/pixel_number * 100))\n",
    "  return first_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a5fd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_levels(warped_prevImg, prevImg_path):#4#(x)\n",
    "  second_bool = False\n",
    "  prevImg = cv2.imread(prevImg_path)\n",
    "    \n",
    "  img_diff = cv2.absdiff(warped_prevImg, prevImg)\n",
    "#   print(img_diff.shape)\n",
    "  sum_img_diff = np.sum(img_diff,axis = 2)\n",
    "#   print(sum_img_diff.shape)\n",
    "#   cv2.imwrite('sabun-result.jpg',img_diff)\n",
    "  average_l1_distance = np.mean(sum_img_diff)\n",
    "#   print(average_l1_distance)\n",
    "  if average_l1_distance < 15:#ハイパーパラメータ\n",
    "    second_bool = True\n",
    "#   print(\"second condition is :{}\".format(average_l1_distance))\n",
    "  return second_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa78627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_difference_v21_v23(flow_map12 ,flow_map23):#5#(o)\n",
    "#   third_bool = False\n",
    "\n",
    "#   flow_map_diff = flow_map23 - flow_map12\n",
    "# #   print(flow_map23)\n",
    "# #   print(\"---------------------\")\n",
    "# #   print(flow_map12)\n",
    "#   # print(\"---------------------\")\n",
    "#   # print(flow_map_diff)\n",
    "#   # print(\"---------------------\")\n",
    "# #   print(flow_map_diff.shape)\n",
    "#   # print(\"---------------------\")\n",
    "    \n",
    "#   flow_map_diff_c1 = flow_map_diff[:,:,0]\n",
    "#   flow_map_diff_c2 = flow_map_diff[:,:,1]\n",
    "#   flow_map_disagreement, _ = cv2.cartToPolar(flow_map_diff_c1, flow_map_diff_c2)\n",
    "#   # print(flow_map_disagreement)\n",
    "#   # print(\"---------------------\")\n",
    "#   # print(flow_map_disagreement)\n",
    "#   flow_map_mean_disagreement = np.mean(flow_map_disagreement)\n",
    "#   #print(flow_map_mean_disagreement)\n",
    "#   # print(np.sqrt((flow_map_diff_c1[0][0])**2 + (flow_map_diff_c2[0][0])**2))\n",
    "\n",
    "#   if flow_map_mean_disagreement < 1.2:#ハイパーパラメータ\n",
    "#     third_bool = True\n",
    "# #   print(\"third condition is :{}\".format(flow_map_mean_disagreement))\n",
    "#   return third_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69ed55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06fea942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fixed_list_ucf(classify = \"Fixed\",div = 0):\n",
    "    cache_list = []\n",
    "    action_list = fetch_ucf_action_list()\n",
    "\n",
    "    classify_dir = os.path.join(r\"D:\\GR_data\\capture_crop_256\",classify)#変更可\n",
    "    for action in action_list:\n",
    "        action_path = os.path.join(classify_dir,action)\n",
    "        each_video_list = os.listdir(action_path)\n",
    "        cache_list.append(each_video_list)\n",
    "    return np.hstack(cache_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3be6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_folder_full_path(folder_name,classify):#ex:file_name = v_ApplyEyeMakeup_g01_c01\n",
    "  #ex:folder_name = frames_v_BenchPress_g24_c04\n",
    "  action_dir = folder_name.split('_')[2]\n",
    "  folder_name = os.path.join(r\"D:\\GR_data\\capture_crop_256\",classify,action_dir,folder_name)#変更可\n",
    "  # folder_name = \"/content/drive/MyDrive/UCF101_every_frame/\" + classify + \"/\"+ action_dir + folder_name\n",
    "#   print(folder_name)\n",
    "  return folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf11422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650741f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "276d1ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_three_frame(frame_folder_path,model):#()\n",
    "#ex:frame_folder = D:\\GR_data\\capture_all_frame\\Fixed\\Archery\\frames_v_Archery_g02_c01\n",
    "  frame_count = 0\n",
    "  triplet_dir_count = 0\n",
    "  triplet_folder = r\"D:\\GR_data\\frame_triplet_dir\"#\n",
    "\n",
    "  split_path_list = frame_folder_path.split(os.sep)\n",
    "  flo_dir_name = os.path.join(triplet_folder,split_path_list[3],split_path_list[4],split_path_list[5])#変更可\n",
    "#ex:flo_dir_name = D:\\GR_data\\frame_triplet_dir\\frame_triplet_dir\\Fixed\\ApplyEyeMakeup\\frames_v_ApplyEyeMakeup_g01_c01\n",
    "\n",
    "\n",
    "  frame_list = os.listdir(frame_folder_path)#frame_folder内のframeのリスト\n",
    "  sorted(frame_list)\n",
    "#   print(frame_list)\n",
    "  last_frame_num = frame_list[-1]\n",
    "  last_frame_num = os.path.splitext(last_frame_num)[0]\n",
    "  last_frame_num = int(last_frame_num)\n",
    "#   print(last_frame_num)\n",
    "\n",
    "#Set the first 3 frames\n",
    "  img1 = os.path.join(frame_folder_path, str(frame_count).zfill(6)+ \".png\")\n",
    "#   print(img1)\n",
    "  img2 = os.path.join(frame_folder_path, str(frame_count+1).zfill(6)+ \".png\")\n",
    "#   print(img2)\n",
    "  img3 = os.path.join(frame_folder_path, str(frame_count+2).zfill(6)+ \".png\")\n",
    "#   print(img3)\n",
    "\n",
    "  while True:\n",
    "    base_path_1 = os.path.basename(img1)\n",
    "    base_path_2 = os.path.basename(img2)\n",
    "    base_path_3 = os.path.basename(img3)\n",
    "    \n",
    "    each_triplet_dir = os.path.join(flo_dir_name,str(triplet_dir_count).zfill(6))#tripletを格納するfolder\n",
    "    \n",
    "    flo1 ,flo2 = flo_out(model,img1,img2,img3)#imgからflowをoutしてそのファイルpathを返す\n",
    "    flow_map12 ,flow_map23 = read_2_flo(flo1,flo2)\n",
    "    flow_magnitude_12,flow_magnitude_23 = flow_magnitude_out(flow_map12,flow_map23)\n",
    "\n",
    "    \n",
    "    first_bool_12 = with_movement_greater_than_3(flow_map12,flow_magnitude_12)\n",
    "    first_bool_23 = with_movement_greater_than_3(flow_map23,flow_magnitude_23)\n",
    "\n",
    "    warped_prevImg2_to_1 = warp_second_frame_to_first(flow_map12,img2)\n",
    "    warped_prevImg3_to_2 = warp_second_frame_to_first(flow_map23,img3)\n",
    "    second_bool_12 = intensity_levels(warped_prevImg2_to_1,img1)\n",
    "    second_bool_23 = intensity_levels(warped_prevImg3_to_2,img2)\n",
    "\n",
    "#     third_bool = average_difference_v21_v23(flow_map12 ,flow_map23)\n",
    "    #2と3の前方flowと1と2の後方flowのマイナスを比較する形に変えたほうがいい??\n",
    "    \n",
    "    if (first_bool_12 and first_bool_23) and (second_bool_12 and second_bool_23):\n",
    "      #Trueなら3frameずらしてtripletのカウントを+1\n",
    "      if not os.path.isdir(each_triplet_dir):\n",
    "        os.makedirs(each_triplet_dir)\n",
    "#         print(each_triplet_dir)\n",
    "      if not os.path.exists(os.path.join(each_triplet_dir,base_path_1)):\n",
    "        shutil.copy(img1,each_triplet_dir)\n",
    "      if not os.path.exists(os.path.join(each_triplet_dir,base_path_2)):\n",
    "        shutil.copy(img2,each_triplet_dir)\n",
    "      if not os.path.exists(os.path.join(each_triplet_dir,base_path_3)):\n",
    "        shutil.copy(img3,each_triplet_dir)\n",
    "      \n",
    "      frame_count += 3\n",
    "      triplet_dir_count += 1\n",
    "    \n",
    "      if frame_count + 2 > last_frame_num:\n",
    "        break\n",
    "      img1 = os.path.join(frame_folder_path, str(frame_count).zfill(6)+ \".png\")\n",
    "      img2 = os.path.join(frame_folder_path, str(frame_count+1).zfill(6)+ \".png\")\n",
    "      img3 = os.path.join(frame_folder_path, str(frame_count+2).zfill(6)+ \".png\")\n",
    "    \n",
    "    else:\n",
    "      frame_count += 1\n",
    "\n",
    "      if frame_count + 2 > last_frame_num:\n",
    "        break\n",
    "      img1 = os.path.join(frame_folder_path, str(frame_count).zfill(6)+ \".png\")\n",
    "      img2 = os.path.join(frame_folder_path, str(frame_count+1).zfill(6)+ \".png\")\n",
    "      img3 = os.path.join(frame_folder_path, str(frame_count+2).zfill(6)+ \".png\")\n",
    "    \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3696d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850ff372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: C:\\Users\\hikar\\Documents\\pwcnet_ft_4x1_300k_sintel_final_384x768.pth\n"
     ]
    }
   ],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8156420d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#試験\n",
    "# choice_three_frame(r\"D:\\GR_data\\capture_crop_256\\Fixed\\PlayingGuitar\\frames_v_PlayingGuitar_g22_c02\",model)#変更可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf6a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4e87007",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2b3b5004554ce19a3575e5fe8e9dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hikar\\anaconda3\\envs\\mmediting_1\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "classify = \"Fixed\" #Unfixed#Fixed\\n\",\n",
    "fetch_frame_folder_list = Fixed_list_ucf()#Fixedの中からframeをfetchしてこなければならない\\n\",\n",
    "# print(fetch_frame_folder_list)\\n\",\n",
    "#↑これでframe_v_～～のfolderのlistまでは取り出せる\\n\",\n",
    "for fetch_path in tqdm(fetch_frame_folder_list):\n",
    "  frame_folder = frame_folder_full_path(fetch_path,classify)#capture_all_frameのフルパスを取得\\n\",\n",
    "  choice_three_frame(frame_folder,model)\n",
    "#   print(frame_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba51f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b928ecf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194b14b499494452960c57400ff8ca9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 指定されたパスが見つかりません。: 'D:\\\\GR_data\\\\frame_triplet_dir\\\\Fixed\\\\ApplyEyeMakeup\\\\frames_v_ApplyEyeMakeup_g01_c01'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15344\\1247624267.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0maction_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0mfull_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfetch_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m   \u001b[0mtriplet_all_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtriplet_all_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 指定されたパスが見つかりません。: 'D:\\\\GR_data\\\\frame_triplet_dir\\\\Fixed\\\\ApplyEyeMakeup\\\\frames_v_ApplyEyeMakeup_g01_c01'"
     ]
    }
   ],
   "source": [
    "#D:\\GR_data\\frame_triplet_dir\\Fixed\\BaseballPitch\\frames_v_BaseballPitch_g22_c04\n",
    "\n",
    "triplet_all_count = 0\n",
    "root_dir = r\"D:\\GR_data\\frame_triplet_dir\"\n",
    "classify = \"Fixed\" #Unfixed#Fixed\n",
    "fetch_frame_folder_list = Fixed_list_ucf()\n",
    "#↑これでframe_v_～～のfolderのlistまでは取り出せる\n",
    "\n",
    "for fetch_path in tqdm(fetch_frame_folder_list):\n",
    "  action_dir = fetch_path.split(\"_\")[2]\n",
    "  full_path = os.path.join(root_dir,classify,action_dir,fetch_path)\n",
    "  triplet_all_count += len(os.listdir(full_path))\n",
    "\n",
    "print(triplet_all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd80ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a1437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
